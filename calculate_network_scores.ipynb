{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf922e29-70e6-440d-90d6-8f9e8ce70ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Anonymous\n",
    "# License: CC-BY-NC-SA 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c64a75e-7ca2-4b2d-a8d4-7bcf8b75f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mapillary/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import contextily as cx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68c6c55-00a5-4a90-98c3-8e5e96ece028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Unified Analysis Configuration ---\n",
      "Outputs will be saved to: /Users/Codes/results/figures\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "print(\"--- Initializing Unified Analysis Configuration ---\")\n",
    "PROJECT_ROOT = os.path.abspath('..') \n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, \"results\")\n",
    "FIGURES_DIR = os.path.join(RESULTS_DIR, \"figures\")\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "print(f\"Outputs will be saved to: {RESULTS_DIR} and {FIGURES_DIR}\")\n",
    "\n",
    "# --- INPUT FILES ---\n",
    "INPUT_CLUSTERS_CSV = os.path.join(RESULTS_DIR, \"full_network_with_clusters.csv\")\n",
    "TEMP_ADJACENCY_PKL = os.path.join(RESULTS_DIR, \"temp_full_adjacency_list.pkl\")\n",
    "\n",
    "# --- OUTPUT FILES ---\n",
    "OUTPUT_METRICS_CSV = os.path.join(RESULTS_DIR, \"final_city_metrics.csv\")\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "# The core, justifiable decision of this analysis.\n",
    "# We define which cluster IDs are considered \"supportive\".\n",
    "SUPPORTIVE_CLUSTER_IDS = [0, 2] # Clusters A and B\n",
    "CRS = \"EPSG:3857\"\n",
    "# Cities for detailed maps, chosen to represent different quadrants in the new typology.\n",
    "CITIES_TO_MAP = [\"paris\", \"san_francisco\", \"boston\", \"hamburg\", \"coimbra\", \"fortaleza\", \"apia\", \"moscow\", \"kyiv\", \"doha\", \"mexico_city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5553f8b5-2571-4d4a-a333-f0b66a4a9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_list(gdf: gpd.GeoDataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Builds a dictionary mapping each segment's unique_edge_id to a list of\n",
    "    its neighboring unique_edge_ids by checking for touching endpoints.\n",
    "    This is the core of the geometric topology inference.\n",
    "    \"\"\"\n",
    "    print(\"Building spatial index for all segment endpoints...\")\n",
    "    # Create a new GeoDataFrame containing every endpoint\n",
    "    endpoints = []\n",
    "    for idx, row in gdf.iterrows():\n",
    "        # Add the start point\n",
    "        endpoints.append({'unique_edge_id': row['unique_edge_id'], 'geometry': Point(row['geometry'].coords[0])})\n",
    "        # Add the end point\n",
    "        endpoints.append({'unique_edge_id': row['unique_edge_id'], 'geometry': Point(row['geometry'].coords[-1])})\n",
    "    \n",
    "    endpoints_gdf = gpd.GeoDataFrame(endpoints, crs=CRS)\n",
    "    spatial_index = endpoints_gdf.sindex\n",
    "\n",
    "    print(\"Inferring network adjacency from endpoint proximity...\")\n",
    "    adjacency = {uid: [] for uid in gdf['unique_edge_id']}\n",
    "    \n",
    "    # Iterate through each segment to find its neighbors\n",
    "    for idx, segment in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Finding Neighbors\"):\n",
    "        uid_self = segment['unique_edge_id']\n",
    "        \n",
    "        # Get start and end points of the current segment\n",
    "        start_node = Point(segment['geometry'].coords[0])\n",
    "        end_node = Point(segment['geometry'].coords[-1])\n",
    "        \n",
    "        # Find all endpoints that are very close to the start_node of our segment\n",
    "        # We use a small buffer (1 meter) to account for tiny floating point inaccuracies\n",
    "        possible_matches_at_start = spatial_index.query(start_node.buffer(1), predicate=\"intersects\")\n",
    "        \n",
    "        for match_idx in possible_matches_at_start:\n",
    "            uid_neighbor = endpoints_gdf.iloc[match_idx]['unique_edge_id']\n",
    "            if uid_neighbor != uid_self: # Don't connect a segment to itself\n",
    "                adjacency[uid_self].append(uid_neighbor)\n",
    "\n",
    "        # Do the same for the end_node\n",
    "        possible_matches_at_end = spatial_index.query(end_node.buffer(1), predicate=\"intersects\")\n",
    "        for match_idx in possible_matches_at_end:\n",
    "            uid_neighbor = endpoints_gdf.iloc[match_idx]['unique_edge_id']\n",
    "            if uid_neighbor != uid_self:\n",
    "                adjacency[uid_self].append(uid_neighbor)\n",
    "\n",
    "    # Clean up the adjacency list by removing duplicate neighbors\n",
    "    for uid, neighbors in adjacency.items():\n",
    "        adjacency[uid] = list(set(neighbors))\n",
    "        \n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d576c20b-3885-4e16-a02b-af85132d3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_core_metrics(city_gdf: gpd.GeoDataFrame, city_adjacency: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculates the two core metrics for a single city:\n",
    "    1. Proportion of Supportive Roads (Quantity)\n",
    "    2. CNRI (Connectivity/Cohesion)\n",
    "    Returns: (psr, cnri, lcc_uids_for_plotting)\n",
    "    \"\"\"\n",
    "    total_city_length = city_gdf['length'].sum()\n",
    "    if total_city_length == 0:\n",
    "        return 0.0, 0.0, set()\n",
    "\n",
    "    supportive_segments_df = city_gdf[city_gdf['cluster'].isin(SUPPORTIVE_CLUSTER_IDS)]\n",
    "    \n",
    "    # --- METRIC 1: PSR (QUANTITY) ---\n",
    "    total_supportive_length = supportive_segments_df['length'].sum()\n",
    "    psr = total_supportive_length / total_city_length\n",
    "    \n",
    "    if supportive_segments_df.empty or total_supportive_length == 0:\n",
    "        return psr, 0.0, set()\n",
    "\n",
    "    # --- METRIC 2: CNRI (CONNECTIVITY) ---\n",
    "    supportive_uids = set(supportive_segments_df['unique_edge_id'])\n",
    "    \n",
    "    G_supportive = nx.Graph()\n",
    "    for uid_self in supportive_uids:\n",
    "        if uid_self in city_adjacency:\n",
    "            for uid_neighbor in city_adjacency[uid_self]:\n",
    "                if uid_neighbor in supportive_uids:\n",
    "                    G_supportive.add_edge(uid_self, uid_neighbor)\n",
    "\n",
    "    if G_supportive.number_of_nodes() == 0:\n",
    "        return psr, 0.0, set()\n",
    "\n",
    "    components = list(nx.connected_components(G_supportive))\n",
    "    if not components:\n",
    "        return psr, 0.0, set()\n",
    "\n",
    "    lcc_uids = max(components, key=len)\n",
    "    lcc_length = supportive_segments_df[supportive_segments_df['unique_edge_id'].isin(lcc_uids)]['length'].sum()\n",
    "    \n",
    "    cnri = lcc_length / total_supportive_length\n",
    "    \n",
    "    return psr, cnri, lcc_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deef41db-f851-4beb-9dc6-aef5dd810aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_city_typology(summary_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generates the new, robust 2D scatter plot based on the two core metrics.\n",
    "    \"\"\"\n",
    "    print(\"Generating City Typology scatter plot...\")\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "    summary_df['Status'] = np.where(summary_df['city_id'].isin(CITIES_TO_MAP), 'Case Study City', 'Other City')\n",
    "    color_palette = {'Case Study City': '#e41a1c', 'Other City': '#377eb8'}\n",
    "\n",
    "    x_axis = 'PSR'\n",
    "    y_axis = 'CNRI'\n",
    "\n",
    "    sns.scatterplot(data=summary_df, x=x_axis, y=y_axis, ax=ax, s=100, alpha=0.9, legend=False,\n",
    "                    edgecolor='black', hue='Status', palette=color_palette,\n",
    "                    hue_order=['Other City', 'Case Study City'])\n",
    "\n",
    "    median_x = summary_df[x_axis].median()\n",
    "    median_y = summary_df[y_axis].median()\n",
    "    ax.axvline(median_x, color='grey', linestyle='--', lw=1.5)\n",
    "    ax.axhline(median_y, color='grey', linestyle='--', lw=1.5)\n",
    "\n",
    "    # Quadrant Labels\n",
    "    ax.text(ax.get_xlim()[1], ax.get_ylim()[1], ' Holistically Ready ', ha='right', va='top', fontsize=14, fontweight='bold', alpha=0.7)\n",
    "    ax.text(ax.get_xlim()[0], ax.get_ylim()[1], ' Efficient Core ', ha='left', va='top', fontsize=14, fontweight='bold', alpha=0.7)\n",
    "    ax.text(ax.get_xlim()[1], ax.get_ylim()[0], ' Fragmented Excellence ', ha='right', va='bottom', fontsize=14, fontweight='bold', alpha=0.7)\n",
    "    ax.text(ax.get_xlim()[0], ax.get_ylim()[0], ' Fundamentally Unready ', ha='left', va='bottom', fontsize=14, fontweight='bold', alpha=0.7)\n",
    "    \n",
    "    # Add text labels for the highlighted cities\n",
    "    for city_id in CITIES_TO_MAP:\n",
    "        city_data = summary_df[summary_df['city_id'] == city_id]\n",
    "        if not city_data.empty:\n",
    "            ax.text(city_data[x_axis].iloc[0], city_data[y_axis].iloc[0] + 0.015, city_id.replace('_', ' ').title(),\n",
    "                    fontsize=11, ha='center', fontweight='bold')\n",
    "\n",
    "    # Titles and labels\n",
    "    ax.set_title('City Typology: Quantity vs. Connectivity of Supportive Infrastructure', fontsize=20, pad=20)\n",
    "    ax.set_xlabel('PSR (by length)', fontsize=14)\n",
    "    ax.set_ylabel('CNRI (Connectivity of Supportive Roads)', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(FIGURES_DIR, \"city_readiness_quadrant_plot.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    print(f\"Definitive typology plot saved to: {output_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d527fd-d979-48c3-afa7-6eb06cd0c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cnri_map(city_gdf: gpd.GeoDataFrame, city_id: str, cnri: float, lcc_uids: set):\n",
    "    \"\"\"\n",
    "    Generates a new, more informative side-by-side map that directly visualizes the CNRI.\n",
    "    \"\"\"\n",
    "    print(f\"Generating CNRI map for '{city_id}'...\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    supportive_network = city_gdf[city_gdf['cluster'].isin(SUPPORTIVE_CLUSTER_IDS)]\n",
    "    \n",
    "    # --- Panel A: All Supportive Infrastructure (The Denominator) ---\n",
    "    city_gdf.plot(ax=ax1, color='lightgray', linewidth=0.5)\n",
    "    if not supportive_network.empty:\n",
    "        supportive_network.plot(ax=ax1, color='cornflowerblue', linewidth=1.5)\n",
    "    cx.add_basemap(ax1, crs=city_gdf.crs.to_string(), source=cx.providers.CartoDB.Positron)\n",
    "    ax1.set_title(f\"A: All Supportive Infrastructure (Clusters A & B)\", fontsize=16)\n",
    "    ax1.set_axis_off()\n",
    "\n",
    "    # --- Panel B: The Largest Connected Component (The Numerator) ---\n",
    "    lcc_network = supportive_network[supportive_network['unique_edge_id'].isin(lcc_uids)]\n",
    "    \n",
    "    city_gdf.plot(ax=ax2, color='lightgray', linewidth=0.5)\n",
    "    if not supportive_network.empty:\n",
    "        # Plot all supportive segments faintly in the background for context\n",
    "        supportive_network.plot(ax=ax2, color='lightcoral', linewidth=0.7)\n",
    "    if not lcc_network.empty:\n",
    "        # Plot the LCC boldly on top\n",
    "        lcc_network.plot(ax=ax2, color='red', linewidth=2.0)\n",
    "    cx.add_basemap(ax2, crs=city_gdf.crs.to_string(), source=cx.providers.CartoDB.Positron)\n",
    "    ax2.set_title(f\"B: Largest Connected Component (LCC)\", fontsize=16)\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    fig.suptitle(f'Core Network Cohesion: {city_id.replace(\"_\", \" \").title()} (CNRI = {cnri:.3f})', fontsize=24)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
    "    \n",
    "    output_path = os.path.join(FIGURES_DIR, f\"map_comparison_{city_id}.png\")\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Comparison map for '{city_id}' saved to: {output_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b420a22-40c9-401f-8d65-6e531db6da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to orchestrate the robust analysis and visualization workflow.\"\"\"\n",
    "    print(\"--- Starting Unified Robust Analysis ---\")\n",
    "\n",
    "    # 1. Load data with cluster assignments\n",
    "    print(f\"Loading data from: {INPUT_CLUSTERS_CSV}...\")\n",
    "    df = pd.read_csv(INPUT_CLUSTERS_CSV, sep=\";\", low_memory=False)\n",
    "    df['geometry'] = gpd.GeoSeries.from_wkt(df['geometry'])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=CRS)\n",
    "    gdf['length'] = pd.to_numeric(gdf['length'], errors='coerce').fillna(0)\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # 2. Load or build the full adjacency list\n",
    "    if os.path.exists(TEMP_ADJACENCY_PKL):\n",
    "        print(f\"Loading pre-computed adjacency list from: {TEMP_ADJACENCY_PKL}\")\n",
    "        full_adjacency_list = joblib.load(TEMP_ADJACENCY_PKL)\n",
    "    else:\n",
    "        print(\"Adjacency list not found. Building it now...\")\n",
    "        full_adjacency_list = build_adjacency_list(gdf)\n",
    "        joblib.dump(full_adjacency_list, TEMP_ADJACENCY_PKL)\n",
    "    print(\"Adjacency list is ready.\")\n",
    "    \n",
    "    # 3. Calculate Core Metrics for each city\n",
    "    print(\"\\nCalculating Core Metrics (PSR & CNRI) for all 100 cities...\")\n",
    "    all_results = []\n",
    "    city_lcc_data = {} # To store LCC UIDs for plotting\n",
    "\n",
    "    for city_id, group in tqdm(gdf.groupby('city_id'), desc=\"Processing Cities\"):\n",
    "        city_uids = set(group['unique_edge_id'])\n",
    "        city_adjacency = {uid: [neighbor for neighbor in full_adjacency_list.get(uid, []) if neighbor in city_uids] \n",
    "                          for uid in city_uids}\n",
    "        \n",
    "        proportion, cnri, lcc_uids = calculate_core_metrics(group.copy(), city_adjacency)\n",
    "        \n",
    "        all_results.append({\n",
    "            'city_id': city_id, \n",
    "            'PSR': proportion,\n",
    "            'CNRI': cnri\n",
    "        })\n",
    "        city_lcc_data[city_id] = lcc_uids\n",
    "\n",
    "    summary_df = pd.DataFrame(all_results).sort_values('CNRI', ascending=False)\n",
    "    \n",
    "    # 4. Save the final, robust metrics\n",
    "    summary_df.to_csv(OUTPUT_METRICS_CSV, index=False)\n",
    "    print(f\"\\n✅ Final city metrics saved to: {OUTPUT_METRICS_CSV}\")\n",
    "    print(\"\\n--- Top 10 Cities by CNRI ---\")\n",
    "    print(summary_df.head(10).to_string())\n",
    "\n",
    "    # 5. Generate all figures\n",
    "    print(\"\\n--- Generating All Figures ---\")\n",
    "    plot_city_typology(summary_df)\n",
    "    \n",
    "    print(\"\\n--- Generating Detailed City Maps ---\")\n",
    "    for city_id in CITIES_TO_MAP:\n",
    "        city_gdf = gdf[gdf['city_id'] == city_id]\n",
    "        city_metrics = summary_df[summary_df['city_id'] == city_id].iloc[0]\n",
    "        plot_cnri_map(city_gdf, city_id, city_metrics['CNRI'], city_lcc_data[city_id])\n",
    "\n",
    "    print(\"\\n--- Unified script complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd0fa68-ad1f-4c0e-9da7-6eaea6fd7f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Unified Robust Analysis ---\n",
      "Loading data from: /Users/results/full_network_with_clusters.csv...\n",
      "Data loaded successfully.\n",
      "Loading pre-computed adjacency list from: /Users/results/temp_full_adjacency_list.pkl\n",
      "Adjacency list is ready.\n",
      "\n",
      "Calculating Core Metrics (Proportion & Core NRI) for all 100 cities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cities: 100%|██████████████████████| 100/100 [00:17<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final city metrics saved to: /Users/results/final_city_metrics.csv\n",
      "\n",
      "--- Top 10 Cities by CNRI ---\n",
      "                   city_id               PSR       CNRI\n",
      "5                     apia               0.043253  0.957332\n",
      "66                  moscow               0.651635  0.937737\n",
      "51                    kyiv               0.556159  0.897225\n",
      "36                    doha               0.174281  0.817649\n",
      "61             mexico_city               0.144383  0.684430\n",
      "84                santiago               0.255517  0.645172\n",
      "20            buenos_aires               0.165147  0.622258\n",
      "68  municipio_de_sao_paulo               0.137207  0.586303\n",
      "79               reykjavik               0.044946  0.574322\n",
      "44                 houston               0.165697  0.540729\n",
      "\n",
      "--- Generating All Figures ---\n",
      "Generating City Typology scatter plot...\n",
      "Definitive typology plot saved to: /Users/results/figures/city_readiness_quadrant_plot.png\n",
      "\n",
      "--- Generating Detailed City Maps ---\n",
      "Generating CNRI map for 'paris'...\n",
      "Comparison map for 'paris' saved to: /Users/results/figures/map_comparison_paris.png\n",
      "Generating CNRI map for 'san_francisco'...\n",
      "Comparison map for 'san_francisco' saved to: /Users/results/figures/map_comparison_san_francisco.png\n",
      "Generating CNRI map for 'boston'...\n",
      "Comparison map for 'boston' saved to: /Users/results/figures/map_comparison_boston.png\n",
      "Generating CNRI map for 'hamburg'...\n",
      "Comparison map for 'hamburg' saved to: /Users/results/figures/map_comparison_hamburg.png\n",
      "Generating CNRI map for 'coimbra'...\n",
      "Comparison map for 'coimbra' saved to: /Users/results/figures/map_comparison_coimbra.png\n",
      "Generating CNRI map for 'fortaleza'...\n",
      "Comparison map for 'fortaleza' saved to: /Users/results/figures/map_comparison_fortaleza.png\n",
      "Generating CNRI map for 'apia'...\n",
      "Comparison map for 'apia' saved to: /Users/results/figures/map_comparison_apia.png\n",
      "Generating CNRI map for 'moscow'...\n",
      "Comparison map for 'moscow' saved to: /Users/results/figures/map_comparison_moscow.png\n",
      "Generating CNRI map for 'kyiv'...\n",
      "Comparison map for 'kyiv' saved to: /Users/results/figures/map_comparison_kyiv.png\n",
      "Generating CNRI map for 'doha'...\n",
      "Comparison map for 'doha' saved to: /Users/results/figures/map_comparison_doha.png\n",
      "Generating CNRI map for 'mexico_city'...\n",
      "Comparison map for 'mexico_city' saved to: /Users/results/figures/map_comparison_mexico_city.png\n",
      "\n",
      "--- Unified script complete. ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787e4f7-2099-4021-8cd1-28451c437a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
